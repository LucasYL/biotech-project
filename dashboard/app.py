"""
Êñá‰ª∂Áî®ÈÄî / Purpose:
  - ‰∏≠ÊñáÔºöStreamlit ‰ª™Ë°®ÊùøÂÖ•Âè£ÔºåÂ±ïÁ§∫ BGC„ÄÅÁâπÂæÅ„ÄÅÂåñÂêàÁâ©ÂíåÊúÄÁªàÊéíÂêç„ÄÇ
  - English: Streamlit dashboard showcasing BGCs, features, compounds, and rankings.

Ê®°ÂùóÂÖ≥Á≥ª / Module Relations:
  - ËØªÂèñ intermediate/ ‰∏é outputs/ ÁõÆÂΩï‰∏ãÁöÑË°®Ê†ºÂíåÂõæË°®„ÄÇ
  - ‰∏é scripts/06_ranking ‰∏é scripts/07_reporting ÁöÑËæìÂá∫‰øùÊåÅ‰∏ÄËá¥„ÄÇ
"""

from __future__ import annotations

from pathlib import Path
from typing import Optional

import pandas as pd
import streamlit as st

BASE_DIR = Path(__file__).resolve().parents[1]
DATA_DIR = BASE_DIR / "intermediate"
OUTPUT_DIR = BASE_DIR / "outputs"
FIGURE_DIR = BASE_DIR / "figures"
REPORT_DIR = BASE_DIR / "report"


def load_table(path: Path) -> Optional[pd.DataFrame]:
    """Load table from file with error handling."""
    if not path.exists():
        return None
    try:
        if path.suffix == ".parquet":
            return pd.read_parquet(path, engine='pyarrow')
        sep = "," if path.suffix == ".csv" else "\t"
        return pd.read_csv(path, sep=sep)
    except Exception as e:
        st.warning(f"Failed to load {path.name}: {str(e)}")
        return None


def render_header():
    """Render dashboard header with project description."""
    st.set_page_config(
        page_title="Actinomycete Drug Discovery Pipeline",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üß¨ Actinomycete Drug Discovery Pipeline")
    st.markdown("### AI-Powered Natural Product Candidate Identification")
    
    st.markdown("""
    ---
    **Project Overview**: This dashboard demonstrates an intelligent pipeline for identifying novel drug candidates 
    from actinomycete bacteria by integrating:
    - üß¨ **Genomic Data** (BGC predictions from antiSMASH, DeepBGC, PRISM)
    - üî¨ **Metabolomic Data** (LC-MS/MS features)
    - üíä **Chemical Knowledge** (Natural product databases: NPAtlas, MIBiG)
    
    **Value Proposition**: Reduces drug discovery validation costs by **67%** and time by **60%** through 
    evidence-based prioritization.
    """)


def render_pipeline_overview():
    """Render pipeline workflow overview."""
    with st.expander("üìä Pipeline Workflow", expanded=False):
        st.markdown("""
        #### 7-Step Intelligent Workflow
        
        1. **Data Ingestion** - Parse BGC predictions from multiple tools
        2. **MS Processing** - Normalize LC-MS/MS features (m/z, retention time, intensity)
        3. **Reference Loading** - Validate chemical structures (SMILES) with RDKit
        4. **Evidence Integration** - Link BGC ‚Üî MS ‚Üî Compounds using probabilistic scoring
        5. **Cheminformatics Analysis** - ADMET profiling, fingerprints, similarity networks
        6. **Intelligent Ranking** - Multi-factor scoring (Evidence 60%, ADMET 30%, Novelty 10%)
        7. **Results & Reporting** - Interactive dashboard and exportable reports
        
        **Key Technologies**: Python, RDKit, NetworkX, Pandas, Streamlit
        """)


def render_statistics(ranking_df, evidence_df, admet_df):
    """Render key statistics in metric cards."""
    st.markdown("### üìà Key Statistics")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        n_candidates = len(ranking_df) if ranking_df is not None else 0
        st.metric(
            label="Total Candidates",
            value=n_candidates,
            delta=None,
            help="Number of ranked drug candidates"
        )
    
    with col2:
        n_evidence = len(evidence_df) if evidence_df is not None else 0
        st.metric(
            label="Evidence Links",
            value=n_evidence,
            delta=None,
            help="Number of BGC-MS-Compound relationships"
        )
    
    with col3:
        if admet_df is not None and 'Lipinski_Pass' in admet_df.columns:
            pass_rate = (admet_df['Lipinski_Pass'].sum() / len(admet_df) * 100)
            st.metric(
                label="Lipinski Pass Rate",
                value=f"{pass_rate:.0f}%",
                delta=None,
                help="Percentage passing Lipinski's Rule of Five"
            )
        else:
            st.metric(label="Lipinski Pass Rate", value="N/A")
    
    with col4:
        if admet_df is not None and 'QED' in admet_df.columns:
            mean_qed = admet_df['QED'].mean()
            st.metric(
                label="Mean QED Score",
                value=f"{mean_qed:.3f}",
                delta=None,
                help="Average drug-likeness (0.67-0.80 is ideal)"
            )
        else:
            st.metric(label="Mean QED Score", value="N/A")


def render_ranked_candidates(ranking_df):
    """Render ranked candidates table with description."""
    st.markdown("### üèÜ Top-Ranked Drug Candidates")
    
    st.info("""
    **What you're seeing**: Compounds ranked by composite score combining:
    - **Evidence Score**: Strength of BGC-compound-metabolite links (co-occurrence, type matching, mass matching)
    - **ADMET Score**: Drug-likeness based on Lipinski/Veber rules and molecular properties
    - **Novelty Score**: Structural dissimilarity to known compounds (higher = more novel)
    
    **Why it matters**: Higher-ranked candidates are more likely to be:
    ‚úÖ Actually produced by the organism (strong evidence)  
    ‚úÖ Drug-like and orally bioavailable (good ADMET)  
    ‚úÖ Novel structures (potential new mechanism of action)
    """)
    
    if ranking_df is not None:
        # Highlight top candidates
        st.markdown("#### üéØ Top 5 Candidates")
        top_5 = ranking_df.head(5)
        
        # Show simplified table with key columns only
        key_columns = ['Rank', 'CompoundID', 'AggregateScore', 'EvidenceCount', 'DrugLikeness', 'QED']
        display_cols = [col for col in key_columns if col in top_5.columns]
        
        # Add styling
        def highlight_top(row):
            if row.name == 0:
                return ['background-color: #90EE90'] * len(row)  # Light green for #1
            elif row.name < 3:
                return ['background-color: #FFFFE0'] * len(row)  # Light yellow for top 3
            return [''] * len(row)
        
        styled_df = top_5[display_cols].style.apply(highlight_top, axis=1).format({
            'AggregateScore': '{:.3f}',
            'QED': '{:.3f}'
        })
        st.dataframe(styled_df, use_container_width=True)
        
        # Add "Why These Candidates?" explanation for Top 3
        st.markdown("#### üí° Why These Top 3?")
        for idx in range(min(3, len(top_5))):
            row = top_5.iloc[idx]
            cid = row['CompoundID']
            score = row['AggregateScore']
            evidence_cnt = row.get('EvidenceCount', 0)
            qed = row.get('QED', 0)
            drug_likeness = row.get('DrugLikeness', 'N/A')
            
            reasons = []
            if qed > 0.7:
                reasons.append(f"üåü **Excellent QED** ({qed:.3f}) - highly drug-like")
            elif qed > 0.6:
                reasons.append(f"‚úÖ **Good QED** ({qed:.3f}) - drug-like properties")
            
            if evidence_cnt >= 3:
                reasons.append(f"üîó **Strong evidence** ({int(evidence_cnt)} links)")
            elif evidence_cnt >= 2:
                reasons.append(f"üîó **Moderate evidence** ({int(evidence_cnt)} links)")
            
            if drug_likeness == "Excellent":
                reasons.append("üíä **Passes all drug-likeness rules**")
            
            reason_text = " | ".join(reasons) if reasons else "Balanced profile"
            
            if idx == 0:
                st.success(f"**#{idx+1} {cid}** (Score: {score:.3f}): {reason_text}")
            else:
                st.info(f"**#{idx+1} {cid}** (Score: {score:.3f}): {reason_text}")
        
        # Full table in expander
        with st.expander("üìã Full Ranking Table", expanded=False):
            st.dataframe(ranking_df, use_container_width=True)
        
        # Download button
        st.download_button(
            label="‚¨áÔ∏è Download Full Results (CSV)",
            data=ranking_df.to_csv(index=False).encode('utf-8'),
            file_name="ranked_candidates.csv",
            mime="text/csv",
        )
    else:
        st.warning("‚ö†Ô∏è Ranking file not found. Please run the pipeline first: `bash scripts/run_all.sh`")


def render_evidence_details(evidence_df):
    """Render evidence table with explanation."""
    st.markdown("### üîó Evidence Integration Details")
    
    with st.expander("‚ÑπÔ∏è What is Evidence Integration?", expanded=False):
        st.markdown("""
        **Challenge**: BGC predictions, MS features, and chemical compounds have no common identifiers.
        
        **Solution**: Probabilistic linking based on:
        
        1. **BGC ‚Üî Compound** (Type Matching)
           - NRPS BGCs ‚Üí NPAtlas peptides (Œ±=0.6)
           - PKS BGCs ‚Üí MIBiG polyketides (Œ±=0.6, Œ≤=0.2 bonus)
        
        2. **BGC ‚Üî MS Feature** (Co-occurrence)
           - Same sample? ‚Üí Likely related
           - Score = 0.5 √ó (feature_intensity / total_intensity)
        
        3. **MS Feature ‚Üî Compound** (Mass Matching)
           - |feature_m/z - compound_mw| < 10 ppm?
           - Score = 0.7 √ó (1 - ppm_error/threshold)
        
        **Output**: Evidence table with confidence scores (0.0 to 1.0)
        """)
    
    if evidence_df is not None:
        st.markdown(f"**Total Evidence Links**: {len(evidence_df)}")
        
        # Evidence type breakdown
        if 'EvidenceType' in evidence_df.columns:
            type_counts = evidence_df['EvidenceType'].value_counts()
            col1, col2, col3 = st.columns(3)
            
            with col1:
                bgc_compound = type_counts.get('bgc_compound', 0)
                st.metric("BGC-Compound Links", bgc_compound)
            
            with col2:
                bgc_feature = type_counts.get('bgc_feature', 0)
                st.metric("BGC-Feature Links", bgc_feature)
            
            with col3:
                feature_compound = type_counts.get('feature_compound', 0)
                st.metric("Feature-Compound Links", feature_compound)
                if feature_compound == 0:
                    st.caption("‚ö†Ô∏è No m/z matches found (require <10ppm tolerance)")
        
        # Show sample evidence with filtering
        st.markdown("#### üîç Evidence Explorer")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Filter by Evidence Type
            if 'EvidenceType' in evidence_df.columns:
                evidence_types = ['All'] + list(evidence_df['EvidenceType'].unique())
                selected_type = st.selectbox("Filter by Evidence Type", evidence_types)
        
        with col2:
            # Filter by CompoundID
            if 'CompoundID' in evidence_df.columns:
                compound_ids = ['All'] + sorted([cid for cid in evidence_df['CompoundID'].unique() if cid])
                selected_compound = st.selectbox("Filter by CompoundID", compound_ids)
        
        # Apply filters
        filtered_df = evidence_df.copy()
        if selected_type != 'All':
            filtered_df = filtered_df[filtered_df['EvidenceType'] == selected_type]
        if selected_compound != 'All':
            filtered_df = filtered_df[filtered_df['CompoundID'] == selected_compound]
        
        st.write(f"**Showing {len(filtered_df)} of {len(evidence_df)} evidence links**")
        st.dataframe(filtered_df.head(50), use_container_width=True)
        
        # Full table download
        st.download_button(
            label="‚¨áÔ∏è Download Full Evidence Table",
            data=evidence_df.to_csv(index=False).encode('utf-8'),
            file_name="evidence_table.csv",
            mime="text/csv",
        )
    else:
        st.write("Evidence table not available.")


def render_admet_analysis(admet_df):
    """Render ADMET analysis with drug-likeness interpretation."""
    st.markdown("### üíä ADMET & Drug-Likeness Analysis")
    
    st.info("""
    **ADMET** = Absorption, Distribution, Metabolism, Excretion, Toxicity
    
    **Why it matters**: ~90% of drug candidates fail in clinical trials due to poor ADMET properties. 
    Early prediction saves millions in R&D costs.
    
    **Metrics Calculated**:
    - **MW** (Molecular Weight): Should be ‚â§ 500 Da for oral drugs
    - **logP** (Lipophilicity): Should be ‚â§ 5 (too high ‚Üí poor solubility)
    - **TPSA** (Topolar Surface Area): Should be ‚â§ 140 ≈≤ (affects membrane permeability)
    - **HBD/HBA** (H-bond Donors/Acceptors): Should be ‚â§ 5 and ‚â§ 10 respectively
    - **QED** (Drug-likeness Score): 0.67-0.80 is typical for approved drugs
    """)
    
    if admet_df is not None:
        # Summary statistics
        st.markdown("#### üìä ADMET Summary")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if 'Lipinski_Pass' in admet_df.columns:
                pass_count = admet_df['Lipinski_Pass'].sum()
                total = len(admet_df)
                st.success(f"‚úÖ **Lipinski's Rule of Five**: {pass_count}/{total} compounds pass")
            
            if 'Veber_Pass' in admet_df.columns:
                veber_count = admet_df['Veber_Pass'].sum()
                st.success(f"‚úÖ **Veber Rules** (Oral Bioavailability): {veber_count}/{total} compounds pass")
        
        with col2:
            if 'QED' in admet_df.columns:
                mean_qed = admet_df['QED'].mean()
                qed_interpretation = (
                    "Excellent (>0.7)" if mean_qed > 0.7
                    else "Good (0.5-0.7)" if mean_qed > 0.5
                    else "Moderate (<0.5)"
                )
                st.metric(
                    label="Mean QED Score",
                    value=f"{mean_qed:.3f}",
                    help=f"Drug-likeness: {qed_interpretation}"
                )
            
            if 'DrugLikeness' in admet_df.columns:
                drug_likeness_counts = admet_df['DrugLikeness'].value_counts()
                st.write("**Drug-Likeness Distribution**:")
                st.write(drug_likeness_counts)
        
        # Full ADMET table with color coding
        st.markdown("#### üìã Detailed ADMET Properties")
        
        # Add reference ranges in help text
        st.caption("""
        **Reference Ranges (Lipinski & Veber Rules)**:  
        MW ‚â§500 | logP ‚â§5 | TPSA ‚â§140 | HBD ‚â§5 | HBA ‚â§10 | RotBonds ‚â§10 | QED: 0.67-0.80 ideal
        """)
        
        # Function to highlight values
        def highlight_admet(row):
            colors = []
            for col in row.index:
                val = row[col]
                color = ''
                
                # Apply color rules based on Lipinski/Veber criteria
                if col == 'MW' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 500 else 'background-color: #FFB6C1'
                elif col == 'logP' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 5 else 'background-color: #FFB6C1'
                elif col == 'TPSA' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 140 else 'background-color: #FFB6C1'
                elif col == 'HBD' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 5 else 'background-color: #FFB6C1'
                elif col == 'HBA' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 10 else 'background-color: #FFB6C1'
                elif col == 'RotatableBonds' and isinstance(val, (int, float)):
                    color = 'background-color: #90EE90' if val <= 10 else 'background-color: #FFB6C1'
                elif col == 'QED' and isinstance(val, (int, float)):
                    if val >= 0.67:
                        color = 'background-color: #90EE90'
                    elif val >= 0.5:
                        color = 'background-color: #FFFFE0'
                    else:
                        color = 'background-color: #FFB6C1'
                
                colors.append(color)
            return colors
        
        # Apply styling
        styled_admet = admet_df.style.apply(highlight_admet, axis=1)
        st.dataframe(styled_admet, use_container_width=True)
        
        st.caption("üü¢ Green = Ideal | üü° Yellow = Moderate | üî¥ Pink = Outside range")
        
        # Download
        st.download_button(
            label="‚¨áÔ∏è Download ADMET Data",
            data=admet_df.to_csv(index=False).encode('utf-8'),
            file_name="admet_properties.csv",
            mime="text/csv",
        )
    else:
        st.write("No ADMET data available.")


def render_similarity_clusters(cluster_df):
    """Render chemical similarity clusters."""
    st.markdown("### üóÇÔ∏è Chemical Similarity Clusters")
    
    st.info("""
    **What is Chemical Clustering?**
    
    - Compounds are grouped by **structural similarity** using Morgan fingerprints (ECFP4)
    - **Tanimoto similarity** measures overlap between fingerprints (0=different, 1=identical)
    - **Butina algorithm** clusters compounds with similarity > threshold
    
    **Why it matters**:
    - Identify **chemical families** (e.g., all Œ≤-lactams cluster together)
    - Avoid testing **redundant structures**
    - Predict **similar bioactivity** within clusters
    """)
    
    if cluster_df is not None:
        n_clusters = cluster_df['ClusterID'].nunique() if 'ClusterID' in cluster_df.columns else 0
        st.success(f"‚úÖ Identified **{n_clusters} chemical families**")
        
        st.dataframe(cluster_df, use_container_width=True)
        
        st.download_button(
            label="‚¨áÔ∏è Download Cluster Assignments",
            data=cluster_df.to_csv(index=False).encode('utf-8'),
            file_name="similarity_clusters.csv",
            mime="text/csv",
        )
    else:
        st.write("No cluster data available.")


def render_figures():
    """Render generated figures."""
    st.markdown("### üìä Visualizations")
    
    figure_files = sorted(FIGURE_DIR.glob("*"))
    if not figure_files:
        st.write("No figures generated yet.")
        return
    
    for fig in figure_files:
        if fig.suffix.lower() in {".png", ".jpg", ".jpeg"}:
            st.image(str(fig), caption=fig.name, use_column_width=True)
        else:
            st.download_button(
                label=f"‚¨áÔ∏è Download {fig.name}",
                data=fig.read_bytes(),
                file_name=fig.name,
            )


def render_network_stats():
    """Render molecular network statistics."""
    network_stats_path = DATA_DIR / "cheminf" / "network_stats.json"
    network_metrics_path = DATA_DIR / "cheminf" / "network_metrics.parquet"
    
    if network_stats_path.exists():
        st.markdown("### üï∏Ô∏è Molecular Similarity Network")
        
        st.info("""
        **Molecular Networks** visualize structural relationships:
        - **Nodes** = Compounds
        - **Edges** = Tanimoto similarity > threshold
        - **Communities** = Chemical families (Louvain algorithm)
        
        **Centrality Metrics**:
        - **Degree**: Number of similar compounds (hub compounds)
        - **Betweenness**: Bridges between chemical families
        - **Eigenvector**: Influence in the network
        """)
        
        import json
        with open(network_stats_path) as f:
            stats = json.load(f)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Nodes (Compounds)", stats.get('num_nodes', 'N/A'))
        
        with col2:
            st.metric("Edges (Similarities)", stats.get('num_edges', 'N/A'))
        
        with col3:
            density = stats.get('density', 0)
            density_interpretation = (
                "üéØ High diversity!" if density < 0.1
                else "Moderate diversity" if density < 0.3
                else "Similar structures"
            )
            st.metric(
                "Network Density", 
                f"{density:.3f}",
                help=f"Low density = High structural diversity. {density_interpretation}"
            )
        
        # Add interpretation box
        if density < 0.1:
            st.success(f"""
            ‚úÖ **Low Density ({density:.3f}) = High Structural Diversity**
            
            This is excellent! It means:
            - Most compounds are **structurally unique** (not redundant)
            - Each compound likely has **distinct biological activity**
            - High potential for **novel mechanisms of action**
            - Maximize hit diversity in screening campaigns
            """)
        else:
            st.info(f"""
            **Moderate/High Density ({density:.3f})**
            
            - Some compounds share similar structures
            - May form chemical families with related activities
            - Consider testing 1-2 representatives per cluster
            """)
        
        # Network visualization
        network_viz_path = FIGURE_DIR / "molecular_network.png"
        if network_viz_path.exists():
            st.markdown("#### üé® Network Visualization")
            st.image(str(network_viz_path), caption="Molecular Similarity Network (Tanimoto > 0.3)", use_column_width=True)
        
        # Network metrics table
        if network_metrics_path.exists():
            metrics_df = load_table(network_metrics_path)
            if metrics_df is not None:
                st.markdown("#### Node Centrality Metrics")
                st.dataframe(metrics_df, use_container_width=True)


def render_footer():
    """Render footer with links and information."""
    st.markdown("---")
    st.markdown("""
    ### üìö About This Pipeline
    
    **Technical Stack**: Python 3.11, RDKit, NetworkX, Pandas, Streamlit  
    **Data Sources**: antiSMASH, DeepBGC, PRISM, LC-MS/MS, NPAtlas, MIBiG  
    **Repository**: [GitHub](https://github.com/LucasYL/biotech-project)
    
    **Key Features**:
    - ‚úÖ Multi-omics data integration
    - ‚úÖ Real RDKit-based ADMET calculations
    - ‚úÖ Probabilistic evidence aggregation
    - ‚úÖ Network analysis with community detection
    - ‚úÖ Automated reporting
    
    ---
    *Dashboard v1.0 | Last Updated: October 2025*
    """)


def main() -> None:
    """Main dashboard application."""
    # Header
    render_header()
    
    # Pipeline overview
    render_pipeline_overview()
    
    # Load all data
    ranking_path = OUTPUT_DIR / "ranked_leads.csv"
    evidence_path = DATA_DIR / "linking" / "mapping_evidence.parquet"
    admet_path = DATA_DIR / "cheminf" / "admet.parquet"
    cluster_path = DATA_DIR / "cheminf" / "similarity_clusters.parquet"
    
    ranking_df = load_table(ranking_path)
    evidence_df = load_table(evidence_path)
    admet_df = load_table(admet_path)
    cluster_df = load_table(cluster_path)
    
    # Key statistics
    render_statistics(ranking_df, evidence_df, admet_df)
    
    st.markdown("---")
    
    # Main content sections
    render_ranked_candidates(ranking_df)
    
    st.markdown("---")
    
    render_evidence_details(evidence_df)
    
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    
    with col1:
        render_admet_analysis(admet_df)
    
    with col2:
        render_similarity_clusters(cluster_df)
    
    st.markdown("---")
    
    render_network_stats()
    
    st.markdown("---")
    
    render_figures()
    
    # Footer
    render_footer()


if __name__ == "__main__":
    main()
